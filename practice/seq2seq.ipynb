{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY3eDXZfiddR"
      },
      "source": [
        "# 불어를 영어로 번역하도록 하는 seq2seq network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuUzdKHoih-l"
      },
      "source": [
        "SOS_token =0\r\n",
        "EOS_token =1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ_QRnCxaXpw"
      },
      "source": [
        "import unicodedata\r\n",
        "import string\r\n",
        "import re\r\n",
        "import random\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb-1xKT6jGrO"
      },
      "source": [
        "SOS_token = 0\r\n",
        "EOS_token = 1\r\n",
        "\r\n",
        "\r\n",
        "class Lang:\r\n",
        "    def __init__(self, name):\r\n",
        "        self.name = name\r\n",
        "        self.word2index = {}\r\n",
        "        self.word2count = {}\r\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n",
        "        self.n_words = 2  # Count SOS and EOS\r\n",
        "\r\n",
        "    def addSentence(self, sentence):\r\n",
        "        for word in sentence.split(' '):\r\n",
        "            self.addWord(word)\r\n",
        "\r\n",
        "    def addWord(self, word):\r\n",
        "        if word not in self.word2index:\r\n",
        "            self.word2index[word] = self.n_words\r\n",
        "            self.word2count[word] = 1\r\n",
        "            self.index2word[self.n_words] = word\r\n",
        "            self.n_words += 1\r\n",
        "        else:\r\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd4ZChgVjgVh"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\r\n",
        "# http://stackoverflow.com/a/518232/2809427\r\n",
        "def unicodeToAscii(s):\r\n",
        "    return ''.join(\r\n",
        "        c for c in unicodedata.normalize('NFD', s)\r\n",
        "        if unicodedata.category(c) != 'Mn'\r\n",
        "    )\r\n",
        "\r\n",
        "# Lowercase, trim, and remove non-letter characters\r\n",
        "\r\n",
        "\r\n",
        "def normalizeString(s):\r\n",
        "    s = unicodeToAscii(s.lower().strip())\r\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV81pNkSc0IO"
      },
      "source": [
        "def normalizeString(s):\r\n",
        "  s = unicodeToAscii(s.lower().strip()) #strip은 앞뒤 제거\r\n",
        "  s = re.sub(r\"([.!?])\", r\" \\1\", s) #대충 대체해서 다듬는단 내용..\r\n",
        "  s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyh0nnf8f-fi"
      },
      "source": [
        "File -> lines -> pairs\r\n",
        "\r\n",
        "File은 영어 -> 다른 언어 이므로,\r\n",
        "다른 언어 -> 영어를 위해 reverse flag 를 추가한다.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clshsKAce9Fa"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\r\n",
        "    print(\"Reading lines...\")\r\n",
        "\r\n",
        "    # Read the file and split into lines\r\n",
        "    lines = open('/content/drive/MyDrive/test/NLP/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\r\n",
        "        read().strip().split('\\n')\r\n",
        "\r\n",
        "    # Split every line into pairs and normalize\r\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\r\n",
        "\r\n",
        "    # Reverse pairs, make Lang instances\r\n",
        "    if reverse:\r\n",
        "        pairs = [list(reversed(p)) for p in pairs]\r\n",
        "        input_lang = Lang(lang2)\r\n",
        "        output_lang = Lang(lang1)\r\n",
        "    else:\r\n",
        "        input_lang = Lang(lang1)\r\n",
        "        output_lang = Lang(lang2)\r\n",
        "\r\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXKoO3mbgjAP",
        "outputId": "3089d265-6f26-4cb4-bb42-a055edcfc479"
      },
      "source": [
        "lines=\"I  am\\n happy\\n  but I\\n am  also\\n  sleepy\"\r\n",
        "print(lines)\r\n",
        "pairs = [[normalizeString(s) for s in l.split('\\t')]for l in lines]\r\n",
        "print(pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I  am\n",
            " happy\n",
            "  but I\n",
            " am  also\n",
            "  sleepy\n",
            "[['i'], [''], [''], ['a'], ['m'], [''], [''], ['h'], ['a'], ['p'], ['p'], ['y'], [''], [''], [''], ['b'], ['u'], ['t'], [''], ['i'], [''], [''], ['a'], ['m'], [''], [''], ['a'], ['l'], ['s'], ['o'], [''], [''], [''], ['s'], ['l'], ['e'], ['e'], ['p'], ['y']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM4NvcDSjC2d"
      },
      "source": [
        "MAX_LENGTH = 10\r\n",
        "\r\n",
        "eng_prefixes = (\r\n",
        "    \"i am \", \"i m \",\r\n",
        "    \"he is\", \"he s \",\r\n",
        "    \"she is\", \"she s\",\r\n",
        "    \"you are\", \"you re \",\r\n",
        "    \"we are\", \"we re \",\r\n",
        "    \"they are\", \"they re \"\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def filterPair(p):\r\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\r\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\r\n",
        "        p[1].startswith(eng_prefixes)\r\n",
        "\r\n",
        "\r\n",
        "def filterPairs(pairs):\r\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "94Y8XoxvhvuR",
        "outputId": "c29edc1d-41c5-4cec-cbb6-ac3c3b1da76e"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\r\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\r\n",
        "    print(pairs[0])\r\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\r\n",
        "    pairs = filterPairs(pairs)\r\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\r\n",
        "    print(\"Counting words...\")\r\n",
        "    for pair in pairs:\r\n",
        "        input_lang.addSentence(pair[0])\r\n",
        "        output_lang.addSentence(pair[1])\r\n",
        "    print(\"Counted words:\")\r\n",
        "    print(input_lang.name, input_lang.n_words)\r\n",
        "    print(output_lang.name, output_lang.n_words)\r\n",
        "    return input_lang, output_lang, pairs\r\n",
        "\r\n",
        "\r\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\r\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "['cc by . france attribution tatoeba .org cm wittydev ', 'va !', 'go .']\n",
            "Read 179904 sentence pairs\n",
            "Trimmed to 0 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 2\n",
            "eng 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9bc05a18fa46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fra'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD8-SxgujIsQ"
      },
      "source": [
        "class EncoderRNN(nn.Module):\r\n",
        "  def __init__(self,input_sie,hidden_size):\r\n",
        "    super(EncoderRNN,self).__init__()\r\n",
        "    self.hidden_size=hidden_size\r\n",
        "\r\n",
        "    self.embedding = nn.Embedding(input_size,hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}